{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90443014",
   "metadata": {},
   "source": [
    "# 🌐🧠 LangGraph: A Library for Building Multi-Agent Workflows with Memory\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 What is **LangGraph**?\n",
    "\n",
    "> 🧩 **LangGraph** is a powerful extension of [LangChain](https://www.langchain.com/) that allows you to build **stateful, multi-step, and multi-agent applications** using graph-based workflows.\n",
    "\n",
    "It's designed to model **reasoning loops**, **memory-aware conversations**, and **autonomous agents** using a **directed graph** of LangChain `Runnable` components.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba55067",
   "metadata": {},
   "source": [
    "## ❓ Why is LangGraph Needed?\n",
    "\n",
    "LangGraph solves real-world problems that plain LangChain sometimes struggles with:\n",
    "\n",
    "| ⚠️ Challenge | ✅ LangGraph Solution |\n",
    "|-------------|------------------------|\n",
    "| Stateless Chains | Maintains **state** across nodes and iterations |\n",
    "| No loops or conditionals | Allows **cycles** and **conditional routing** |\n",
    "| Hard to coordinate multiple agents | Graphs allow **coordination & memory sharing** |\n",
    "| Limited control flow | You can model **if/else**, **for**, **while**, etc. |\n",
    "\n",
    "> 💡 Perfect for use cases like **RAG pipelines**, **autonomous agents**, **multi-step reasoning**, and **tool-enhanced LLM workflows**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae1354",
   "metadata": {},
   "source": [
    "## 🧱 Core Components of LangGraph\n",
    "\n",
    "### 1. 🔁 `StateGraph`\n",
    "\n",
    "- The main structure where you define:\n",
    "  - Nodes (steps or actions)\n",
    "  - Edges (transitions between nodes)\n",
    "  - Conditions, loops, and entry/exit points\n",
    "- Think of it like a **flowchart** for your logic.\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(state_type=dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f6649",
   "metadata": {},
   "source": [
    "### 2. 📌 `Nodes (add_node)`\n",
    "- Each node is a LangChain Runnable (e.g. an LLM call, a tool, a function).\n",
    "\n",
    "- Added via add_node(name, runnable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef628b83",
   "metadata": {},
   "source": [
    "### 3. 🔄 `Edges and Flow (add_edge, add_conditional_edges)`\n",
    "\n",
    "Define flow between nodes:\n",
    "\n",
    "- add_edge(\"A\", \"B\") connects node A to B\n",
    "\n",
    "- add_conditional_edges(\"node\", condition_fn) lets you route based on outp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b43e2",
   "metadata": {},
   "source": [
    "### 4. 🎯 `Entry and Exit Points`\n",
    "set_entry_point(\"start\") – where the graph begins\n",
    "\n",
    "set_finish_point(\"end\") – terminal state of the flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1512d0f",
   "metadata": {},
   "source": [
    "### 5. `🛠️ Runnable Functions and LangChain Tools`\n",
    "\n",
    "LangGraph nodes are built on LangChain Runnables – meaning you can use:\n",
    "\n",
    "- LLM chains (e.g. PromptTemplate + LLM + OutputParser)\n",
    "\n",
    "- Tool use (e.g. Search, Math)\n",
    "\n",
    "- Memory (e.g. ConversationBufferMemory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28118e26",
   "metadata": {},
   "source": [
    "### 6. 💾 `Memory (via State Object)`\n",
    "LangGraph tracks state as a Python dictionary across the workflow.\n",
    "\n",
    "- You can include chat history, tool outputs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f337c915",
   "metadata": {},
   "source": [
    "### 📦 Example Use Cases\n",
    "- 🧠 Autonomous Agents: With memory and multi-tool planning\n",
    "\n",
    "- 📚 RAG Pipelines: Search, retrieve, generate, validate\n",
    "\n",
    "- 🤖 Multi-Agent Chatbots: Different personalities working together\n",
    "\n",
    "- 🧪 Workflow Orchestration: Tool use + decision-making over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cc2cd",
   "metadata": {},
   "source": [
    "# `Reflection Agent`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f177dd5",
   "metadata": {},
   "source": [
    "## 🪞🤖 LangGraph Reflection Agent: Intelligent Self-Correction for LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3852b12c",
   "metadata": {},
   "source": [
    "## 📌 What is a **Reflection Agent**?\n",
    "\n",
    "> 🧠 A **Reflection Agent** in LangGraph is an advanced agent that can **evaluate**, **critique**, and **refine its own outputs** by leveraging multiple LLM passes and memory.\n",
    "\n",
    "It uses a **multi-step loop** where the agent:\n",
    "1. Proposes an initial response\n",
    "2. Reflects on it using a critique\n",
    "3. Improves the output based on feedback\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08683eb",
   "metadata": {},
   "source": [
    "## 🧠 Why Use a Reflection Agent?\n",
    "\n",
    "| 🔍 Problem | 🪞 Reflection Agent Solves |\n",
    "|------------|----------------------------|\n",
    "| LLM gives mediocre or incorrect answers | Allows self-critique and iterative improvement |\n",
    "| No quality control in vanilla agents | Introduces structured reasoning & reflection |\n",
    "| One-shot outputs are unreliable | Iteratively polishes the answer before presenting it |\n",
    "\n",
    "> ✅ Ideal for complex reasoning, fact-checking, writing, and analysis tasks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecdf57f",
   "metadata": {},
   "source": [
    "## 🔁 How It Works (LangGraph Architecture)\n",
    "\n",
    "### 🧩 Nodes\n",
    "\n",
    "| 🧱 Node | 📝 Description |\n",
    "|--------|----------------|\n",
    "| `generate` | The LLM generates an initial answer |\n",
    "| `reflect` | The LLM critiques the answer and identifies flaws |\n",
    "| `improve` | The LLM refines the answer based on reflection |\n",
    "| `final` | Final output is returned after one or more reflection loops |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4fa62",
   "metadata": {},
   "source": [
    "### 🔄 Graph Loop\n",
    "\n",
    "LangGraph allows **loops** in the graph, enabling multiple `reflect → improve` cycles until the answer is satisfactory.\n",
    "\n",
    "```python\n",
    "workflow.add_edge(\"generate\", \"reflect\")\n",
    "workflow.add_edge(\"reflect\", \"improve\")\n",
    "workflow.add_edge(\"improve\", \"reflect\")  # loop\n",
    "workflow.add_edge(\"improve\", \"final\")    # exit conditionally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a628a5",
   "metadata": {},
   "source": [
    "🛠️ Core Components\n",
    "✅ Runnable Nodes\n",
    "Each step is a LangChain Runnable like a LLMChain with:\n",
    "\n",
    "- PromptTemplate\n",
    "\n",
    "- LLM\n",
    "\n",
    "- OutputParser\n",
    "\n",
    "``` python\n",
    "\n",
    "generate_chain = RunnableSequence([...])\n",
    "reflect_chain = RunnableSequence([...])\n",
    "improve_chain = RunnableSequence([...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cfcefb",
   "metadata": {},
   "source": [
    "\n",
    "### 🧠 State Object\n",
    "Keeps track of:\n",
    "- Current answer\n",
    "- Reflections\n",
    "- Iteration count\n",
    "- Chat history\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"input\": \"What is LangGraph?\",\n",
    "  \"draft\": \"...\",\n",
    "  \"reflection\": \"...\",\n",
    "  \"iteration\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde5096",
   "metadata": {},
   "source": [
    "### 📌 Entry & Exit\n",
    "``` python\n",
    "\n",
    "workflow.set_entry_point(\"generate\")\n",
    "workflow.set_finish_point(\"final\")\n",
    "\n",
    "- 🔁 Exit Condition\n",
    "- Reflection loops stop based on:\n",
    "\n",
    "- Max iterations (e.g. 3 attempts)\n",
    "- Confidence score\n",
    "\n",
    "- Quality detection logic in reflect node\n",
    "\n",
    "- You define that with a conditional router.\n",
    "\n",
    "- workflow.add_conditional_edges(\"improve\", condition_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d822b2",
   "metadata": {},
   "source": [
    "### 💡 Example Use Cases\n",
    "✍️ Essay Writing: Draft → Reflect → Improve for better quality\n",
    "\n",
    "🤔 Q&A Bots: More accurate and nuanced answers\n",
    "\n",
    "📚 Code Generation: Validate/refactor LLM-generated code\n",
    "\n",
    "🔬 Scientific Reasoning: Reduce hallucinations with self-checks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80135da4",
   "metadata": {},
   "source": [
    "### 🪞 Reflection Agent Pattern in LangChain (Jupyter Markdown Format)\n",
    "\n",
    "Here’s a well-structured **Jupyter Notebook Markdown** explanation of the **Reflection Agent pattern** in LangChain — including motivation, structure, and usage 👇\n",
    "\n",
    "---\n",
    "\n",
    "```markdown\n",
    "# 🪞 LangChain Reflection Agent Pattern\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 What is the Reflection Pattern?\n",
    "\n",
    "> 🔁 The **Reflection Agent Pattern** is a reasoning loop that enables an LLM to **critically assess its own outputs** and **refine them through self-feedback** — inspired by how humans revise drafts.\n",
    "\n",
    "It uses a **Critique → Revise → Repeat** mechanism to **improve answer quality**, **reduce hallucinations**, and **increase coherence**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Why Use It?\n",
    "\n",
    "| 💡 Problem | 🛠️ Solution with Reflection |\n",
    "|-----------|-----------------------------|\n",
    "| LLMs hallucinate | Catch and correct inconsistencies |\n",
    "| First draft is poor | Allow iterative self-improvement |\n",
    "| No external feedback | Simulate peer review with self-critiques |\n",
    "\n",
    "This pattern **boosts reliability and robustness** in open-ended reasoning tasks. 🧠✅\n",
    "\n",
    "---\n",
    "\n",
    "## 🔄 The Reflection Cycle\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "   ┌──────────────┐\n",
    "   │   Generate   │\n",
    "   └─────┬────────┘\n",
    "         ▼\n",
    "   ┌──────────────┐\n",
    "   │   Reflect    │ 🔍\n",
    "   └─────┬────────┘\n",
    "         ▼\n",
    "   ┌──────────────┐\n",
    "   │   Revise     │ ✍️\n",
    "   └─────┬────────┘\n",
    "         ▼\n",
    "   ┌──────────────┐\n",
    "   │   Final?     │ ✅\n",
    "   └─────┬────────┘\n",
    "     Yes │    │ No\n",
    "         ▼    ▼\n",
    "     Return  Reflect Again\n",
    "```\n",
    "\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 Components of the Pattern\n",
    "\n",
    "### 1️⃣ **Generation Phase**\n",
    "\n",
    "The LLM produces an initial output for a user question.\n",
    "\n",
    "```python\n",
    "llm_chain = LLMChain(prompt=initial_prompt, llm=model)\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "### 2️⃣ **Reflection Phase**\n",
    "\n",
    "A **second prompt** is used to **critique** the first response.\n",
    "\n",
    "```python\n",
    "reflection_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful critic. Review the following answer and list its flaws or improvements.\n",
    "Answer: {draft}\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3️⃣ **Revision Phase**\n",
    "\n",
    "Using the critique, the LLM generates an improved response.\n",
    "\n",
    "```python\n",
    "revision_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Here is an answer and feedback. Write an improved version.\n",
    "Answer: {draft}\n",
    "Feedback: {critique}\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 State Structure\n",
    "\n",
    "A dictionary (`dict`) that tracks all state during the loop:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"input\": \"What is LangChain?\",\n",
    "  \"draft\": \"...initial output...\",\n",
    "  \"reflection\": \"...critique...\",\n",
    "  \"improved\": \"...revised output...\",\n",
    "  \"iteration\": 2\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 Loop Control\n",
    "\n",
    "You can loop using:\n",
    "\n",
    "* ✅ **Fixed iterations**\n",
    "* 🧠 **Satisfaction check** (e.g., “Is this now correct?”)\n",
    "\n",
    "```python\n",
    "if iteration >= max_iterations or reflection says \"Good\":\n",
    "    exit\n",
    "else:\n",
    "    loop again\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Where to Use It\n",
    "\n",
    "* ✍️ Long-form writing assistants\n",
    "* 🤖 Complex QA bots\n",
    "* 🧪 Scientific explanation agents\n",
    "* 📜 Legal and policy document generation\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Final Takeaway\n",
    "\n",
    "> The **Reflection Agent Pattern** in LangChain empowers agents with the ability to **self-correct** — making them more reliable and thoughtful in their responses.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔗 References\n",
    "\n",
    "* [LangChain Blog: Reflection Pattern](https://blog.langchain.dev/reflexion-a-language-agent-with-verbal-reasoning/)\n",
    "* [LangGraph Reflection Agents](https://docs.langchain.com/langgraph/agents/reflection/)\n",
    "* [LangChain Agent Patterns](https://docs.langchain.com/docs/expression-language/patterns)\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8daef",
   "metadata": {},
   "source": [
    "# 🌟 Types of Reflector Agents in LangChain\n",
    "\n",
    "Reflection agents are designed to **reflect** on their prior responses and **revise** based on self-evaluation. Different types focus on different **strategies of reflection** 🔄🧠\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ 🪞 Basic Critique-Based Reflector\n",
    "\n",
    "### ✅ Description:\n",
    "- The agent **generates a draft**\n",
    "- Then **critiques** the output\n",
    "- And finally **revises** it using that critique\n",
    "\n",
    "### 🔁 Loop:\n",
    "\n",
    "Draft → Critique → Revise → Final Output\n",
    "\n",
    "### 📦 Tools used:\n",
    "- `LLMChain` for generation\n",
    "- PromptTemplate for critique and revision\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf9b6e",
   "metadata": {},
   "source": [
    "\n",
    "### 2️⃣ 🧮 Score-Based Reflector (Graded Reflection)\n",
    "\n",
    "### ✅ Description:\n",
    "- The agent **assigns a numerical score** (e.g., 1–10) to its answer\n",
    "- If the score is low, it **regenerates**\n",
    "- Often used in conjunction with another tool or rubric\n",
    "\n",
    "### 🔁 Loop:\n",
    "\n",
    "Answer → Self-Score → (Retry if score < threshold)\n",
    "---\n",
    "\n",
    "### 3️⃣ 🔄 Chain-of-Thought Reflector\n",
    "✅ Description:\n",
    "Reflects within the reasoning chain\n",
    "\n",
    "Looks at how the answer was reached and not just the final output\n",
    "\n",
    "Great for step-by-step reasoning tasks\n",
    "\n",
    "🧠 Good for:\n",
    "- Math problems\n",
    "- Coding tasks\n",
    "- Multi-hop QA\n",
    "\n",
    "---\n",
    "\n",
    "### 4️⃣ ✨ Plan-Execute Reflector\n",
    "✅ Description:\n",
    "Agent first plans a response structure\n",
    "\n",
    "Executes the plan step-by-step\n",
    "\n",
    "Reflects on each step (like a checkpoint)\n",
    "\n",
    "🧠 Useful for:\n",
    "Multi-step workflows\n",
    "\n",
    "- Content generation with structure\n",
    "\n",
    "---\n",
    "\n",
    "### 5️⃣ 🤝 Multi-Agent Reflection (Peer Review)\n",
    "✅ Description:\n",
    "One agent generates the answer\n",
    "\n",
    "Another agent acts as reviewer\n",
    "\n",
    "Can be looped with multiple revisions\n",
    "\n",
    "🧠 Good for:\n",
    "Debate-style answers\n",
    "\n",
    "Higher quality consensus-based outputs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5cf08e",
   "metadata": {},
   "source": [
    "| 🪞 Reflector Type          | 💡 Strategy                      | ✅ Use Case                           |\n",
    "| -------------------------- | -------------------------------- | ------------------------------------ |\n",
    "| Basic Critique             | Critique and revise              | General QA, content improvement      |\n",
    "| Score-Based                | Self-evaluation (rating)         | Quality-controlled tasks             |\n",
    "| Chain-of-Thought Reflector | Step-by-step reflection          | Math, reasoning, code                |\n",
    "| Plan-Execute Reflector     | Pre-plan and execute w/ feedback | Structured writing, workflows        |\n",
    "| Multi-Agent Reflector      | Peer review between agents       | High-stakes output, creative writing |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444cea2",
   "metadata": {},
   "source": [
    "# 🌐 Understanding **Message Graph** in LangGraph\n",
    "\n",
    "- A **Message Graph** in LangGraph is a workflow pattern where **messages** (such as chat turns, tool calls, or agent actions) are passed between nodes in a directed graph. Each node processes the current state (including the message history) and outputs a new message or modifies the state.\n",
    "\n",
    "- **Purpose:** To model conversational flows, multi-agent chats, or tool-augmented reasoning as a sequence of message exchanges.\n",
    "- **How it works:** Each node in the graph represents a step (e.g., an agent, a tool, a function). The state object tracks the evolving message history and other context.\n",
    "- **Benefits:** Enables complex, memory-aware, multi-step conversations and workflows, supporting loops, branching, and coordination between agents or tools.\n",
    "\n",
    "> **Example:** In a multi-agent chatbot, each agent node receives the conversation history, generates a new message, and passes it along the graph, allowing for dynamic, stateful interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e18d10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 What is a Message Graph?\n",
    "\n",
    "A **Message Graph** in LangGraph is a **graph-based execution model** where **messages** (i.e., data objects or states) are passed between nodes (functions, agents, or tools). \n",
    "\n",
    "It **replaces linear sequences** with a **flexible, branching, state-driven structure**.\n",
    "\n",
    "> 🚀 **Use Case**: Ideal for complex multi-agent workflows, autonomous agents, and RAG pipelines where state/context needs to evolve over time.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 **Core Concepts of Message Graph**\n",
    "\n",
    "| Concept 🔹 | Description |\n",
    "|-----------|-------------|\n",
    "| **Node** | A computation unit (function/agent/tool) that processes input and emits output. |\n",
    "| **Edge** | A transition rule that decides which node to call next based on the output. |\n",
    "| **Message** | A dictionary-like object holding the current state/data being passed. |\n",
    "| **State** | A special message that is preserved and updated as the graph flows. |\n",
    "\n",
    "---\n",
    "\n",
    "## 🌈 **Why Message Graphs?**\n",
    "\n",
    "✅ **Dynamic branching** based on logic  \n",
    "✅ **Memory of previous state**  \n",
    "✅ Easy to create **feedback loops / reflections**  \n",
    "✅ Facilitates **autonomy and multi-step reasoning**\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Example Structure\n",
    "\n",
    "```python\n",
    "from langgraph.graph import MessageGraph\n",
    "\n",
    "# Initialize message graph\n",
    "graph = MessageGraph()\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"start\", start_fn)\n",
    "graph.add_node(\"analyze\", analyze_fn)\n",
    "graph.add_node(\"decide\", decide_fn)\n",
    "\n",
    "# Add edges\n",
    "graph.set_entry_point(\"start\")\n",
    "graph.add_edge(\"start\", \"analyze\")\n",
    "graph.add_edge(\"analyze\", \"decide\")\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa7d37",
   "metadata": {},
   "source": [
    "🧠 Note: Each node receives a state (dictionary) and returns an updated version of it.\n",
    "\n",
    "🧠 State Management in Message Graph\n",
    "🟡 Messages = Dict[str, Any]\n",
    "🔁 State is updated in-place as it flows through the graph.\n",
    "\n",
    "Example state:\n",
    "\n",
    "{\n",
    "  \"question\": \"What is LangGraph?\",\n",
    "  \"thoughts\": [],\n",
    "  \"history\": []\n",
    "}\n",
    "Each node:\n",
    "\n",
    "- 📝 Reads from this state\n",
    "\n",
    "- 🛠️ Updates or appends values\n",
    "\n",
    "- 🧭 Guides which edge to follow based on updated data\n",
    "\n",
    "- 🚦 Control Flow: Conditional Routing\n",
    "\n",
    "``` python\n",
    "\n",
    "def router(state):\n",
    "    if state[\"confidence\"] > 0.8:\n",
    "        return \"final_answer\"\n",
    "    return \"ask_user\"\n",
    "\n",
    "graph.add_node(\"router\", router)\n",
    "graph.add_conditional_edges(\"router\", {\n",
    "    \"final_answer\": \"final\",\n",
    "    \"ask_user\": \"user_input\"\n",
    "})\n",
    "🎯 This makes the graph adaptive, capable of decision-making.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f78f0",
   "metadata": {},
   "source": [
    "🎯 Summary\n",
    "Feature\tDescription\n",
    "🧠 Memory\tMaintains evolving state\n",
    "🔀 Flow Control\tDynamic routing based on logic\n",
    "🤖 Agents Friendly\tWorks well with tools, agents, LLMs\n",
    "🔁 Loops Supported\tGreat for iterations, reflection, etc.\n",
    "\n",
    "> 🧵 Message Graphs are stateful, declarative, and highly composable, making them ideal for building robust AI workflows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245c8fdd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
